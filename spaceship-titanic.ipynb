{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spaceship Titanic Competition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Jimmy Bierenbroodspot, Maarten de Jue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Business Understanding](#Business-Understanding)\n",
    "- [Data Understanding](#Data-Understanding)\n",
    "    - [Load Dataframes](#Load-Dataframes)\n",
    "    - [Dataframe Shape](#Dataframe-Shape)\n",
    "    - [Description Table](#Description-Table)\n",
    "    - [Column Datatypes](#Column-Datatypes)\n",
    "        - [Datatype Table](#Datatype-Table)\n",
    "- [Data Preparation](#Data-Preparation)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Modeling](#Modeling)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This competition is about a spaceship which has collided with a time anomaly where about half of the passengers were transported to a different dimension.\n",
    "\n",
    "Our job is to predict which passengers will get transported and which not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To table of contents](#Table-of-Contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off the data understanding by actually importing the datasets. We have two datasets:\n",
    "\n",
    "- `train_df` which contains a column for whether a passenger is transported or not.\n",
    "- `test_df` this dataset does not contain the target column and should. We are supposed to add the transported column to this dataset and submit it for the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "train_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's take a look at how much data we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The train dataframe contains {train_df.shape[0]} rows and {train_df.shape[1]} columns.')\n",
    "print(f'The test dataframe contains {test_df.shape[0]} rows and {test_df.shape[1]} columns.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have roughly two-thirds of the dataframe to train with and one-thirds of the dataset to predict. The test dataframe contains one fewer column which makes sense as it does not contain the `Transported` column since we are supposed to predict it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the `14` columns and what kind of data they contain. We are going to focus on `train_df` for now since it contains the same data as `test_df` but includes the target column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see an anomaly with `PassengerId`. Normally for ID's you would expect solely a number, although this is not strictly necessary, it is the most common format. According to [this article from the competition](https://www.kaggle.com/competitions/spaceship-titanic/data) everything left from the underscore is the group the passenger belongs to and everything right of the underscore is the number of the passenger within the group. So `0001_01` would be passenger number `01` of group `0001`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To table of contents](#Table-of-Contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although a previously mentioned article contains a description of every column already, it is perhaps a good idea to copy it over anyway for ease of use."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column name | Description |\n",
    "| - | - |\n",
    "| PassengerId | A unique Id for each passenger. Each Id takes the form `gggg_pp` where `gggg` indicates a group the passenger is traveling with and `pp` is their number within the group. People in a group are often family members, but not always. |\n",
    "| HomePlanet | The planet the passenger departed from, typically their planet of permanent residence. |\n",
    "| CryptoSleep | Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins. |\n",
    "| Cabin | The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either `P` for *Port* or `S` for *Starboard* |\n",
    "| Destination | The planet the passenger will be debarking to. |\n",
    "| Age | The age of the passenger. |\n",
    "| VIP | Whether the passenger has paid for special VIP service during the voyage. |\n",
    "| RoomService | Amount the passenger has billed at each of the *Spaceship Titanic*'s many luxury amenities. |\n",
    "| FoodCourt | Amount the passenger has billed at each of the *Spaceship Titanic*'s many luxury amenities. |\n",
    "| ShoppingMall | Amount the passenger has billed at each of the *Spaceship Titanic*'s many luxury amenities. |\n",
    "| Spa | Amount the passenger has billed at each of the *Spaceship Titanic*'s many luxury amenities. |\n",
    "| VRDeck | Amount the passenger has billed at each of the *Spaceship Titanic*'s many luxury amenities. |\n",
    "| Name | The first and last names of the passenger. |\n",
    "| Transported | Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Datatypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check whether the the datatype of each column is as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatype at first glance seem to make, except for `Age`. Unless the age is measured with decimals e.g. thirty-and-a-half is `30.5` you would expect the age to be an integer. We can check whether this is the case by using the python `is_integer()` on every value in the column. This function can take float values and return `True` or `False` based on whether the float contains decimal numbers or not. With that we can generate a `Series` containing just `True`s and `False`s. If we look at the unique vales we can see if there's only integers when it only says `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_is_int = train_df['Age'].apply(float.is_integer)\n",
    "\n",
    "tuple(age_is_int.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Age column also contains decimal numbers. We can use a boolean mask to find out what these values are. We can use the previously declared `age_is_int Series` and apply it as a boolean mask but we only want the `False` values so we use a bitwise not operator (`~`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(train_df['Age'][~age_is_int].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it becomes clear that there are actually no decimal numbers and that the anomaly causing `False` to show up are `NaN` values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `object` datatypes doesn't tell us much. We can apply the `type()` function to every row in the `PassengerId, HomePlanet, CryoSleep, Cabin, Destination, VIP, Name` to find out whether the datatype actually makes sense or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_dtype_columns = ['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'VIP', 'Name']\n",
    "\n",
    "for column in object_dtype_columns:\n",
    "    print(f'{column:12} contains the datatypes:', train_df[column].apply(type).unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see most of the columns contains the `float` datatype. This doesn't make sense for the columns which have an `str` datatype as well for example. What we do know is that numpy `NaN` values are seen as `float`s by python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The datatype of np.NAN is: {type(np.NAN)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all the `float` values are actually `NaN`s then we could figure that out by looking at the unique values with the `float` datatype for every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in object_dtype_columns:\n",
    "    curr_column_series = train_df[column]\n",
    "    check_if_float = lambda x: type(x) is float  # A function that checks whether the datatype of a value is a float\n",
    "\n",
    "    float_values = curr_column_series[curr_column_series.map(check_if_float)]  # A series containing only the values with datatype float.\n",
    "\n",
    "    print(f'The unique float values of {column} are: {float_values.unique()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatype Table "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put the correct datatypes neatly in a table."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column name | Datatype |\n",
    "| - | - |\n",
    "| PassengerId | `str` |\n",
    "| HomePlanet | `str` |\n",
    "| CryptoSleep | `bool` |\n",
    "| Cabin | `str` |\n",
    "| Destination | `str` |\n",
    "| Age | `int` |\n",
    "| VIP | `bool` |\n",
    "| RoomService | `float` |\n",
    "| FoodCourt | `float` |\n",
    "| ShoppingMall | `float` |\n",
    "| Spa | `float` |\n",
    "| VRDeck | `float` |\n",
    "| Name | `str` |\n",
    "| Transported | `bool` |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To table of contents](#Table-of-Contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## PassengerId\n",
    "\n",
    "As the PassengerId columns contains 2 pieces of information: the group ID and the ID within the group. We'll separate these into their own columns. Let's have a look at a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"PassengerId\"]].sample(2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Group ID and ID within group are separated by an underscore. We can easily split them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"GroupId\", \"IdWithinGroup\"]] = train_df[\"PassengerId\"].str.split(\"_\", n=2, expand=True)\n",
    "train_df[[\"GroupId\", \"IdWithinGroup\"]].sample(2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It appears as though we split the strings successfully. Let's verify the datatypes of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"GroupId\", \"IdWithinGroup\"]].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The IDs are represented by whole numbers. We probably won't be using math on these IDs, but we might as well store them as integers.\n",
    "\n",
    "This way we should also find out if any values are not formatted as whole numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .astype() raises errors if not formatted properly\n",
    "train_df[[\"GroupId\", \"IdWithinGroup\"]] = train_df[[\"GroupId\", \"IdWithinGroup\"]].astype(int)\n",
    "train_df[[\"GroupId\", \"IdWithinGroup\"]].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wonderful. We can drop the original column, as we probably won't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Groups\n",
    "\n",
    "As it might be interesting to involve information about the groups that passengers are in the data analysis, we can aggregate some information about them into a new DataFrame.\n",
    "\n",
    "We are interested in aggregating the following data:\n",
    "\n",
    "- Amount of people in group.\n",
    "- Lupus et Agnus ad Rivum veniunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = train_df.groupby(\"GroupId\").agg({\n",
    "    \"IdWithinGroup\": len  # Amount of people in group. Random column, doesn't matter for result.\n",
    "    # Add more functions to aggregate on here if so desired\n",
    "})\n",
    "\n",
    "group_df = group_df.rename(\n",
    "    columns={\n",
    "        \"IdWithinGroup\": \"PeopleAmount\"\n",
    "    }\n",
    ")\n",
    "\n",
    "group_df.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[To table of contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To table of contents](#Table-of-Contents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[To table of contents](#Table-of-Contents)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
